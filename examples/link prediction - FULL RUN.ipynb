{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import time\n",
    "import scipy\n",
    "import sklearn\n",
    "from sklearn import cluster, linear_model\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "import sys\n",
    "import warnings # Silence perf warning\n",
    "\n",
    "sys.path.append(os.path.realpath('..'))\n",
    "\n",
    "import nodevectors\n",
    "import csrgraph as cg\n",
    "from csrgraph import methods\n",
    "from nodevectors.evaluation import link_pred\n",
    "from nodevectors.evaluation import graph_eval\n",
    "\n",
    "# UMAP to test (on pip)\n",
    "import umap\n",
    "\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "def nx_node_weights(G, method, **kwargs):\n",
    "    \"\"\"Node Weights through networkX API\"\"\"\n",
    "    pr = np.zeros(len(G))\n",
    "    prdict = method(G, **kwargs)\n",
    "    for i in G.nodes:\n",
    "        pr[i] = prdict[i]\n",
    "    return pr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Availability\n",
    "\n",
    "Data for these notebooks can be found here: https://github.com/VHRanger/Graph-Data\n",
    "Just download it and point the graph generation methods below to it\n",
    "\n",
    "The data is in a different repo to avoid polluting the pip package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### CONFIG\n",
    "TEST_SIZE = 0.2\n",
    "OUT_FILE = 'email.csv'\n",
    "SEED = 42\n",
    "ALL_COMPONENTS = [1, 2, 4, 8, 16, 32, 64, 128, 256]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### GRAPHS\n",
    "#### Uncomment one to choose which graph to run evaluation on\n",
    "\n",
    "#### Artificial random graphs\n",
    "# G = nx.binomial_graph(700, 0.6)\n",
    "G, labels = graph_eval.make_cluster_graph(n_nodes=820, n_clusters=18, connections=1000, drop_pct=0.5)\n",
    "# G, labels = graph_eval.make_weighed_cluster_graph(n_nodes=500, n_clusters=6, connections=1500, drop_pct=0.2, max_edge_weight=15)\n",
    "#### Social graphs\n",
    "# G, labels = graph_eval.make_blogcatalog(dedupe=True)\n",
    "# G, mlabels = graph_eval.make_blogcatalog(dedupe=False)\n",
    "# G, labels = graph_eval.make_email()\n",
    "# G, labels = graph_eval.get_karateclub(\"facebook\") # twitch, github, facebook, wikipedia\n",
    "# G = graph_eval.get_from_snap(url=\"http://snap.stanford.edu/data/facebook_combined.txt.gz\", sep=' ', header=None, comment='#')\n",
    "#### Biology Graphs\n",
    "# G, mlabels = graph_eval.get_n2v_ppi(\"../data/bioNEV/node2vec_PPI\")\n",
    "\n",
    "\n",
    "#### Needs OutOfBounds Nodes support from CSRGraphs to work\n",
    "# G = graph_eval.get_drugbank_ddi(\"../data/bioNEV/DrugBank_DDI\")\n",
    "# G, mlabels = graph_eval.get_mashup_ppi(\"../data/bioNEV/Mashup_PPI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clusters: 18\n",
      "Nodes: 820\n",
      "Edges: 9658\n",
      "connected: True\n"
     ]
    }
   ],
   "source": [
    "#### For Link Prediction: Split graph into train and test edge sets\n",
    "#### (All nodes are still present in both)\n",
    "G_train, testing_pos_edges = link_pred.split_train_test_graph(G, testing_ratio=TEST_SIZE)\n",
    "\n",
    "#### Lazy way to set up evaluation\n",
    "try:\n",
    "    y = labels.label\n",
    "    n_clusters = y.nunique()\n",
    "    HAS_LABELS = True\n",
    "    print(f\"clusters: {n_clusters}\")\n",
    "except:\n",
    "    try: # Multilabels \n",
    "        y = MultiLabelBinarizer().fit_transform(mlabels.mlabels)\n",
    "        HAS_LABELS = True\n",
    "        print(f\"multilabels: {y.shape[1]}\")\n",
    "    except: # No Labels\n",
    "        HAS_LABELS = False\n",
    "        print(\"No Labels\")\n",
    "NNODES = len(G)\n",
    "print(f\"Nodes: {NNODES}\\nEdges: {len(G.edges)}\\nconnected: {nx.is_connected(G_train)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "-------N: 1--------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.1498\t:   1%|▏         | 88/6000 [00:02<03:04, 32.13it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converged! Loss: 0.1484\n",
      "Time: 3.0665\n",
      "Link Prediction:\n",
      "\t(logit) AUC-ROC: 0.517, AUC-PR: 0.463, Acc: 0.509, F1: 0.488\n",
      "\t(lgbm)  AUC-ROC: 0.772, AUC-PR: 0.700, Acc: 0.735, F1: 0.784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.1475\t:   1%|▏         | 86/6000 [00:00<00:10, 562.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converged! Loss: 0.1490\n",
      "Label Prediction:\n",
      "\t(logit) Acc: 0.091, F1 micro: 0.091, F1 macro: 0.091\n",
      "\t(lgbm) Acc: 0.165, F1 micro: 0.165, F1 macro: 0.165\n",
      "MI: 0.37, RAND 0.32, FM: 0.32\n"
     ]
    }
   ],
   "source": [
    "### GGVEC ####\n",
    "for N_COMPONENTS in ALL_COMPONENTS:\n",
    "    print(f\"\\n\\n-------N: {N_COMPONENTS}--------\")\n",
    "    ggvec_params = dict(\n",
    "        n_components=N_COMPONENTS,\n",
    "        order=1,\n",
    "        tol=0.05,\n",
    "        tol_samples=75,\n",
    "        max_epoch=6_000,\n",
    "        learning_rate=0.05,\n",
    "        negative_ratio=0.33,\n",
    "        exponent=0.33,\n",
    "        verbose=True,\n",
    "    )\n",
    "    start_t = time.time()\n",
    "    time.sleep(0.3)\n",
    "    w_train = nodevectors.GGVec(**ggvec_params).fit_transform(G_train)\n",
    "    print(f\"Time: {time.time() - start_t :.4f}\")\n",
    "    lpred = link_pred.LinkPrediction(w_train, G, G_train, testing_pos_edges)\n",
    "\n",
    "    lpred['algorithm'] = 'ggvec'\n",
    "    lpred['dim'] = N_COMPONENTS\n",
    "    lpred['time'] = str(f\"{time.time() - start_t :.1f}\")\n",
    "    lpred = pd.DataFrame([pd.Series(lpred)])\n",
    "    time.sleep(0.3)\n",
    "    LPRED_FILE = \"linkpred_\" + OUT_FILE\n",
    "    if os.path.isfile(LPRED_FILE):\n",
    "        lpred.to_csv(LPRED_FILE, mode='a', header=False, float_format='%.3f')\n",
    "    else:\n",
    "        lpred.to_csv(LPRED_FILE, float_format='%.3f')\n",
    "\n",
    "\n",
    "    w = nodevectors.GGVec(**ggvec_params).fit_transform(G)\n",
    "    labelpred = graph_eval.print_labeled_tests(w, y, test_size=TEST_SIZE, seed=SEED)\n",
    "\n",
    "    labelpred['algorithm'] = 'ggvec'\n",
    "    labelpred['dim'] = N_COMPONENTS\n",
    "    labelpred['time'] = str(f\"{time.time() - start_t :.1f}\")\n",
    "    labelpred = pd.DataFrame([pd.Series(labelpred)])\n",
    "    time.sleep(0.3)\n",
    "    LPRED_FILE = OUT_FILE\n",
    "    if os.path.isfile(OUT_FILE):\n",
    "        labelpred.to_csv(OUT_FILE, mode='a', header=False, float_format='%.3f')\n",
    "    else:\n",
    "        labelpred.to_csv(OUT_FILE, float_format='%.3f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "-------N: 1--------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0341\t:   3%|▎         | 15/500 [00:00<00:01, 265.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converged! Loss: 0.0339\n",
      "Time: 1.2681\n",
      "Link Prediction:\n",
      "\t(logit) AUC-ROC: 0.466, AUC-PR: 0.436, Acc: 0.486, F1: 0.504\n",
      "\t(lgbm)  AUC-ROC: 0.819, AUC-PR: 0.776, Acc: 0.760, F1: 0.783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0335\t:   3%|▎         | 16/500 [00:00<00:01, 257.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converged! Loss: 0.0336\n",
      "Label Prediction:\n",
      "\t(logit) Acc: 0.177, F1 micro: 0.177, F1 macro: 0.177\n",
      "\t(lgbm) Acc: 0.293, F1 micro: 0.293, F1 macro: 0.293\n",
      "MI: 0.31, RAND 0.30, FM: 0.30\n"
     ]
    }
   ],
   "source": [
    "### GGVEC - 2 ####\n",
    "for N_COMPONENTS in ALL_COMPONENTS:\n",
    "    print(f\"\\n\\n-------N: {N_COMPONENTS}--------\")\n",
    "    ggvec_params = dict(\n",
    "        n_components=N_COMPONENTS,\n",
    "        order=2,\n",
    "        tol=0.1,\n",
    "        tol_samples=10,\n",
    "        max_epoch=500,\n",
    "        learning_rate=0.1,\n",
    "        negative_ratio=0.1,\n",
    "        exponent=0.33,\n",
    "        verbose=True,\n",
    "    )\n",
    "    start_t = time.time()\n",
    "    time.sleep(0.3)\n",
    "    w_train = nodevectors.GGVec(**ggvec_params).fit_transform(G_train)\n",
    "    print(f\"Time: {time.time() - start_t :.4f}\")\n",
    "    lpred = link_pred.LinkPrediction(w_train, G, G_train, testing_pos_edges)\n",
    "\n",
    "    lpred['algorithm'] = 'ggvec2'\n",
    "    lpred['dim'] = N_COMPONENTS\n",
    "    lpred['time'] = str(f\"{time.time() - start_t :.1f}\")\n",
    "    lpred = pd.DataFrame([pd.Series(lpred)])\n",
    "    time.sleep(0.3)\n",
    "    LPRED_FILE = \"linkpred_\" + OUT_FILE\n",
    "    if os.path.isfile(LPRED_FILE):\n",
    "        lpred.to_csv(LPRED_FILE, mode='a', header=False, float_format='%.3f')\n",
    "    else:\n",
    "        lpred.to_csv(LPRED_FILE, float_format='%.3f')\n",
    "\n",
    "\n",
    "    w = nodevectors.GGVec(**ggvec_params).fit_transform(G)\n",
    "    labelpred = graph_eval.print_labeled_tests(w, y, test_size=TEST_SIZE, seed=SEED)\n",
    "\n",
    "    labelpred['algorithm'] = 'ggvec2'\n",
    "    labelpred['dim'] = N_COMPONENTS\n",
    "    labelpred['time'] = str(f\"{time.time() - start_t :.1f}\")\n",
    "    labelpred = pd.DataFrame([pd.Series(labelpred)])\n",
    "    time.sleep(0.3)\n",
    "    LPRED_FILE = OUT_FILE\n",
    "    if os.path.isfile(OUT_FILE):\n",
    "        labelpred.to_csv(OUT_FILE, mode='a', header=False, float_format='%.3f')\n",
    "    else:\n",
    "        labelpred.to_csv(OUT_FILE, float_format='%.3f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "-------N: 1--------\n",
      "Making walks... Done, T=1.21\n",
      "Mapping Walk Names... Done, T=1.01\n",
      "Training W2V... Done, T=3.06\n",
      "Time: 5.3080\n",
      "Link Prediction:\n",
      "\t(logit) AUC-ROC: 0.520, AUC-PR: 0.471, Acc: 0.510, F1: 0.505\n",
      "\t(lgbm)  AUC-ROC: 0.781, AUC-PR: 0.729, Acc: 0.718, F1: 0.759\n",
      "Making walks... Done, T=0.13\n",
      "Mapping Walk Names... Done, T=1.16\n",
      "Training W2V... Done, T=2.81\n",
      "Label Prediction:\n",
      "\t(logit) Acc: 0.110, F1 micro: 0.110, F1 macro: 0.110\n",
      "\t(lgbm) Acc: 0.183, F1 micro: 0.183, F1 macro: 0.183\n",
      "MI: -0.00, RAND 0.23, FM: 0.23\n"
     ]
    }
   ],
   "source": [
    "### N2V ####\n",
    "for N_COMPONENTS in ALL_COMPONENTS:\n",
    "    print(f\"\\n\\n-------N: {N_COMPONENTS}--------\")\n",
    "    n2v_params = dict(\n",
    "        n_components=N_COMPONENTS,\n",
    "        epochs=20,\n",
    "        walklen=60,\n",
    "        return_weight=1.,\n",
    "        neighbor_weight=1.,\n",
    "        w2vparams={\n",
    "            \"window\":3, \n",
    "            \"negative\":5, \n",
    "            \"iter\":2,\n",
    "            \"batch_words\":128}\n",
    "    )\n",
    "    start_t = time.time()\n",
    "    w_train = nodevectors.Node2Vec(**n2v_params).fit_transform(G_train)\n",
    "    print(f\"Time: {time.time() - start_t :.4f}\")\n",
    "    lpred = link_pred.LinkPrediction(w_train, G, G_train, testing_pos_edges)\n",
    "\n",
    "    lpred['algorithm'] = 'node2vec'\n",
    "    lpred['dim'] = N_COMPONENTS\n",
    "    lpred['time'] = str(f\"{time.time() - start_t :.1f}\")\n",
    "    lpred = pd.DataFrame([pd.Series(lpred)])\n",
    "    time.sleep(0.3)\n",
    "    LPRED_FILE = \"linkpred_\" + OUT_FILE\n",
    "    if os.path.isfile(LPRED_FILE):\n",
    "        lpred.to_csv(LPRED_FILE, mode='a', header=False, float_format='%.3f')\n",
    "    else:\n",
    "        lpred.to_csv(LPRED_FILE, float_format='%.3f')\n",
    "\n",
    "\n",
    "    w = nodevectors.Node2Vec(**n2v_params).fit_transform(G)\n",
    "    labelpred = graph_eval.print_labeled_tests(w, y, test_size=TEST_SIZE, seed=SEED)\n",
    "\n",
    "    labelpred['algorithm'] = 'node2vec'\n",
    "    labelpred['dim'] = N_COMPONENTS\n",
    "    labelpred['time'] = str(f\"{time.time() - start_t :.1f}\")\n",
    "    labelpred = pd.DataFrame([pd.Series(labelpred)])\n",
    "    time.sleep(0.3)\n",
    "    LPRED_FILE = OUT_FILE\n",
    "    if os.path.isfile(OUT_FILE):\n",
    "        labelpred.to_csv(OUT_FILE, mode='a', header=False, float_format='%.3f')\n",
    "    else:\n",
    "        labelpred.to_csv(OUT_FILE, float_format='%.3f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "-------N: 1--------\n",
      "Time: 0.0400\n",
      "Link Prediction:\n",
      "\t(logit) AUC-ROC: 0.555, AUC-PR: 0.552, Acc: 0.592, F1: 0.656\n",
      "\t(lgbm)  AUC-ROC: 0.720, AUC-PR: 0.653, Acc: 0.675, F1: 0.752\n",
      "Label Prediction:\n",
      "\t(logit) Acc: 0.024, F1 micro: 0.024, F1 macro: 0.024\n",
      "\t(lgbm) Acc: 0.024, F1 micro: 0.024, F1 macro: 0.024\n",
      "MI: -0.00, RAND 0.23, FM: 0.23\n"
     ]
    }
   ],
   "source": [
    "### ProNE ####\n",
    "for N_COMPONENTS in ALL_COMPONENTS:\n",
    "    print(f\"\\n\\n-------N: {N_COMPONENTS}--------\")\n",
    "    pne_params = dict(\n",
    "        n_components=N_COMPONENTS,\n",
    "        step=5,\n",
    "        mu=0.2,\n",
    "        theta=0.5,\n",
    "    )\n",
    "    start_t = time.time()\n",
    "    w_train = nodevectors.ProNE(**pne_params).fit_transform(G_train)\n",
    "    print(f\"Time: {time.time() - start_t :.4f}\")\n",
    "    lpred = link_pred.LinkPrediction(w_train, G, G_train, testing_pos_edges)\n",
    "\n",
    "    lpred['algorithm'] = 'prone'\n",
    "    lpred['dim'] = N_COMPONENTS\n",
    "    lpred['time'] = str(f\"{time.time() - start_t :.1f}\")\n",
    "    lpred = pd.DataFrame([pd.Series(lpred)])\n",
    "    time.sleep(0.3)\n",
    "    LPRED_FILE = \"linkpred_\" + OUT_FILE\n",
    "    if os.path.isfile(LPRED_FILE):\n",
    "        lpred.to_csv(LPRED_FILE, mode='a', header=False, float_format='%.3f')\n",
    "    else:\n",
    "        lpred.to_csv(LPRED_FILE, float_format='%.3f')\n",
    "\n",
    "\n",
    "    w = nodevectors.ProNE(**pne_params).fit_transform(G)\n",
    "    labelpred = graph_eval.print_labeled_tests(w, y, test_size=TEST_SIZE, seed=SEED)\n",
    "\n",
    "    labelpred['algorithm'] = 'prone'\n",
    "    labelpred['dim'] = N_COMPONENTS\n",
    "    labelpred['time'] = str(f\"{time.time() - start_t :.1f}\")\n",
    "    labelpred = pd.DataFrame([pd.Series(labelpred)])\n",
    "    time.sleep(0.3)\n",
    "    LPRED_FILE = OUT_FILE\n",
    "    if os.path.isfile(OUT_FILE):\n",
    "        labelpred.to_csv(OUT_FILE, mode='a', header=False, float_format='%.3f')\n",
    "    else:\n",
    "        labelpred.to_csv(OUT_FILE, float_format='%.3f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 37.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "-------N: 1--------\n",
      "Time: 0.0507\n",
      "Link Prediction:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t(logit) AUC-ROC: 0.519, AUC-PR: 0.572, Acc: 0.517, F1: 0.540\n",
      "\t(lgbm)  AUC-ROC: 0.895, AUC-PR: 0.865, Acc: 0.821, F1: 0.829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 54.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Prediction:\n",
      "\t(logit) Acc: 0.024, F1 micro: 0.024, F1 macro: 0.024\n",
      "\t(lgbm) Acc: 0.354, F1 micro: 0.354, F1 macro: 0.354\n",
      "MI: -0.00, RAND 0.23, FM: 0.23\n"
     ]
    }
   ],
   "source": [
    "### GRaRep ####\n",
    "for N_COMPONENTS in ALL_COMPONENTS:\n",
    "    print(f\"\\n\\n-------N: {N_COMPONENTS}--------\")\n",
    "    grarep_params = dict(\n",
    "        n_components=N_COMPONENTS,\n",
    "        order=1,\n",
    "        embedder=TruncatedSVD(\n",
    "            n_iter=10,\n",
    "            random_state=42),\n",
    "        merger=(lambda x : np.sum(x, axis=0)),\n",
    "    )\n",
    "    start_t = time.time()\n",
    "    w_train = nodevectors.GraRep(**grarep_params).fit_transform(G_train)\n",
    "    print(f\"Time: {time.time() - start_t :.4f}\")\n",
    "    lpred = link_pred.LinkPrediction(w_train, G, G_train, testing_pos_edges)\n",
    "\n",
    "    lpred['algorithm'] = 'grarep'\n",
    "    lpred['dim'] = N_COMPONENTS\n",
    "    lpred['time'] = str(f\"{time.time() - start_t :.1f}\")\n",
    "    lpred = pd.DataFrame([pd.Series(lpred)])\n",
    "    time.sleep(0.3)\n",
    "    LPRED_FILE = \"linkpred_\" + OUT_FILE\n",
    "    if os.path.isfile(LPRED_FILE):\n",
    "        lpred.to_csv(LPRED_FILE, mode='a', header=False, float_format='%.3f')\n",
    "    else:\n",
    "        lpred.to_csv(LPRED_FILE, float_format='%.3f')\n",
    "\n",
    "\n",
    "    w = nodevectors.GraRep(**grarep_params).fit_transform(G)\n",
    "    labelpred = graph_eval.print_labeled_tests(w, y, test_size=TEST_SIZE, seed=SEED)\n",
    "\n",
    "    labelpred['algorithm'] = 'grarep'\n",
    "    labelpred['dim'] = N_COMPONENTS\n",
    "    labelpred['time'] = str(f\"{time.time() - start_t :.1f}\")\n",
    "    labelpred = pd.DataFrame([pd.Series(labelpred)])\n",
    "    time.sleep(0.3)\n",
    "    LPRED_FILE = OUT_FILE\n",
    "    if os.path.isfile(OUT_FILE):\n",
    "        labelpred.to_csv(OUT_FILE, mode='a', header=False, float_format='%.3f')\n",
    "    else:\n",
    "        labelpred.to_csv(OUT_FILE, float_format='%.3f')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "-------N: 1--------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 83/6000 [00:02<03:00, 32.78it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 4.1126\n",
      "Link Prediction:\n",
      "\t(logit) AUC-ROC: 0.502, AUC-PR: 0.449, Acc: 0.504, F1: 0.502\n",
      "\t(lgbm)  AUC-ROC: 0.797, AUC-PR: 0.730, Acc: 0.756, F1: 0.797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 116/6000 [00:00<00:40, 144.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Prediction:\n",
      "\t(logit) Acc: 0.189, F1 micro: 0.189, F1 macro: 0.189\n",
      "\t(lgbm) Acc: 0.244, F1 micro: 0.244, F1 macro: 0.244\n",
      "MI: 0.34, RAND 0.31, FM: 0.31\n"
     ]
    }
   ],
   "source": [
    "### GLoVe with random walks ###\n",
    "for N_COMPONENTS in ALL_COMPONENTS:\n",
    "    print(f\"\\n\\n-------N: {N_COMPONENTS}--------\")\n",
    "    glove_params = dict(\n",
    "        n_components=N_COMPONENTS,\n",
    "        tol=0.001,\n",
    "        max_epoch=6_000,\n",
    "        learning_rate=0.01, \n",
    "        max_loss=10.,\n",
    "        max_count=50, \n",
    "        exponent=0.5,\n",
    "    )\n",
    "    start_t = time.time()\n",
    "    wg = cg.csrgraph(G_train).random_walk_resample(walklen=7, epochs=30)\n",
    "    w_train = nodevectors.Glove(**glove_params).fit_transform(wg)\n",
    "    print(f\"Time: {time.time() - start_t :.4f}\")\n",
    "    lpred = link_pred.LinkPrediction(w_train, G, G_train, testing_pos_edges)\n",
    "\n",
    "    lpred['algorithm'] = 'glove'\n",
    "    lpred['dim'] = N_COMPONENTS\n",
    "    lpred['time'] = str(f\"{time.time() - start_t :.1f}\")\n",
    "    lpred = pd.DataFrame([pd.Series(lpred)])\n",
    "    time.sleep(0.3)\n",
    "    LPRED_FILE = \"linkpred_\" + OUT_FILE\n",
    "    if os.path.isfile(LPRED_FILE):\n",
    "        lpred.to_csv(LPRED_FILE, mode='a', header=False, float_format='%.3f')\n",
    "    else:\n",
    "        lpred.to_csv(LPRED_FILE, float_format='%.3f')\n",
    "\n",
    "    wg = cg.csrgraph(G).random_walk_resample(walklen=7, epochs=30)\n",
    "    w = nodevectors.Glove(**glove_params).fit_transform(wg)\n",
    "    labelpred = graph_eval.print_labeled_tests(w, y, test_size=TEST_SIZE, seed=SEED)\n",
    "\n",
    "    labelpred['algorithm'] = 'glove'\n",
    "    labelpred['dim'] = N_COMPONENTS\n",
    "    labelpred['time'] = str(f\"{time.time() - start_t :.1f}\")\n",
    "    labelpred = pd.DataFrame([pd.Series(labelpred)])\n",
    "    time.sleep(0.3)\n",
    "    LPRED_FILE = OUT_FILE\n",
    "    if os.path.isfile(OUT_FILE):\n",
    "        labelpred.to_csv(OUT_FILE, mode='a', header=False, float_format='%.3f')\n",
    "    else:\n",
    "        labelpred.to_csv(OUT_FILE, float_format='%.3f')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
